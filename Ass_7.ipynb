{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFeQ+7eZDfd6UrWAf5tqQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saniaa2715/DSDBA/blob/main/Ass_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l4dsySdqgqw2"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn8xXAbXhUbN",
        "outputId": "7ca9274b-053e-4aec-c130-acc72bb13443"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "text= 'Never be so kind you forget to be clever. Never be so clever you forget to be kind. '\n",
        "\n",
        "print(\"Word tokenizer\")\n",
        "tokens_words=word_tokenize(text)\n",
        "print(tokens_words)\n",
        "\n",
        "print(\"Sentence tokenizer\")\n",
        "tokens_sent=sent_tokenize(text)\n",
        "print(tokens_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VcJLC-bilYs",
        "outputId": "02ad3f31-7a1f-4855-cfbe-4ac06a735630"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word tokenizer\n",
            "['Never', 'be', 'so', 'kind', 'you', 'forget', 'to', 'be', 'clever', '.', 'Never', 'be', 'so', 'clever', 'you', 'forget', 'to', 'be', 'kind', '.']\n",
            "Sentence tokenizer\n",
            "['Never be so kind you forget to be clever.', 'Never be so clever you forget to be kind.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Tagging\n",
        "\n",
        "from nltk import pos_tag\n",
        "\n",
        "print(\"Parts of speech: \",pos_tag(tokens_words) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfbfFwYJkAmt",
        "outputId": "48b1f784-47e1-47dc-bdea-15187a5814c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parts of speech:  [('Never', 'RB'), ('be', 'VB'), ('so', 'RB'), ('kind', 'NN'), ('you', 'PRP'), ('forget', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('clever', 'RB'), ('.', '.'), ('Never', 'RB'), ('be', 'VB'), ('so', 'RB'), ('clever', 'JJ'), ('you', 'PRP'), ('forget', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('kind', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop Words Removal\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words=set(stopwords.words('english'))\n",
        "filtered_tokens=[]\n",
        "for token in tokens_words:\n",
        "  if token not in stop_words:\n",
        "    filtered_tokens.append(token)\n",
        "\n",
        "print(\"Original text: \", text)\n",
        "print(\"\\n Filtered text: \", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0GfjkEOlJP9",
        "outputId": "6956a73f-fc6b-4705-daad-4a9babaaaad4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:  Never be so kind you forget to be clever. Never be so clever you forget to be kind. \n",
            "\n",
            " Filtered text:  ['Never', 'kind', 'forget', 'clever', '.', 'Never', 'clever', 'forget', 'kind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "stemming = PorterStemmer()\n",
        "\n",
        "stemmed_words = []\n",
        "for token in filtered_tokens:\n",
        "  stemmer = stemming.stem(token)\n",
        "  stemmed_words.append(stemmer)\n",
        "print(stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7Ktkb7AnNBl",
        "outputId": "3fcc8b80-e2b8-4e31-8b99-ecfc88965182"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['never', 'kind', 'forget', 'clever', '.', 'never', 'clever', 'forget', 'kind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_words = []\n",
        "for token in filtered_tokens:\n",
        "  lemmatized = lemmatizer.lemmatize(token)\n",
        "  lemmatized_words.append(lemmatized)\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX0gMjY3tZHs",
        "outputId": "500a00d4-5770-4145-ef86-76019e9980e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Never', 'kind', 'forget', 'clever', '.', 'Never', 'clever', 'forget', 'kind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Term Frequency and Inverse Document Frequency\n",
        "\n",
        "# TF(t,d)=(Number of times term t appears in document d) / (Total number of terms in document d)\n",
        "\n",
        "# IDF = log( Number of documents in the corpus/ Number of documents in the corpus contain the term )\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "docs = [ \"Messi is the greatest player of all times\",\n",
        " \"Ronaldo is Portugal's all-time leading goalscorer and captain\",\n",
        " \"Neymar is key player for the Brazilian national team\",\n",
        " \"Suarez is prolific goalscorer known for his finishing and movement off the ball\"]\n",
        "\n",
        "vectorizer = TfidfVectorizer(analyzer = \"word\", norm = None , use_idf = True , smooth_idf=True)\n",
        "Mat = vectorizer.fit(docs)\n",
        "Mat.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkwS12MYvBte",
        "outputId": "40878053-8e5d-4192-91f8-e54bac037d49"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messi': 14,\n",
              " 'is': 10,\n",
              " 'the': 26,\n",
              " 'greatest': 8,\n",
              " 'player': 20,\n",
              " 'of': 18,\n",
              " 'all': 0,\n",
              " 'times': 28,\n",
              " 'ronaldo': 23,\n",
              " 'portugal': 21,\n",
              " 'time': 27,\n",
              " 'leading': 13,\n",
              " 'goalscorer': 7,\n",
              " 'and': 1,\n",
              " 'captain': 4,\n",
              " 'neymar': 17,\n",
              " 'key': 11,\n",
              " 'for': 6,\n",
              " 'brazilian': 3,\n",
              " 'national': 16,\n",
              " 'team': 25,\n",
              " 'suarez': 24,\n",
              " 'prolific': 22,\n",
              " 'known': 12,\n",
              " 'his': 9,\n",
              " 'finishing': 5,\n",
              " 'movement': 15,\n",
              " 'off': 19,\n",
              " 'ball': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix = vectorizer.transform(docs)\n",
        "print(tfidf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNqUj-SByv8w",
        "outputId": "1d306d48-dd5e-4dce-d9fd-91de7f0af7aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 28)\t1.916290731874155\n",
            "  (0, 26)\t1.2231435513142097\n",
            "  (0, 20)\t1.5108256237659907\n",
            "  (0, 18)\t1.916290731874155\n",
            "  (0, 14)\t1.916290731874155\n",
            "  (0, 10)\t1.0\n",
            "  (0, 8)\t1.916290731874155\n",
            "  (0, 0)\t1.5108256237659907\n",
            "  (1, 27)\t1.916290731874155\n",
            "  (1, 23)\t1.916290731874155\n",
            "  (1, 21)\t1.916290731874155\n",
            "  (1, 13)\t1.916290731874155\n",
            "  (1, 10)\t1.0\n",
            "  (1, 7)\t1.5108256237659907\n",
            "  (1, 4)\t1.916290731874155\n",
            "  (1, 1)\t1.5108256237659907\n",
            "  (1, 0)\t1.5108256237659907\n",
            "  (2, 26)\t1.2231435513142097\n",
            "  (2, 25)\t1.916290731874155\n",
            "  (2, 20)\t1.5108256237659907\n",
            "  (2, 17)\t1.916290731874155\n",
            "  (2, 16)\t1.916290731874155\n",
            "  (2, 11)\t1.916290731874155\n",
            "  (2, 10)\t1.0\n",
            "  (2, 6)\t1.5108256237659907\n",
            "  (2, 3)\t1.916290731874155\n",
            "  (3, 26)\t1.2231435513142097\n",
            "  (3, 24)\t1.916290731874155\n",
            "  (3, 22)\t1.916290731874155\n",
            "  (3, 19)\t1.916290731874155\n",
            "  (3, 15)\t1.916290731874155\n",
            "  (3, 12)\t1.916290731874155\n",
            "  (3, 10)\t1.0\n",
            "  (3, 9)\t1.916290731874155\n",
            "  (3, 7)\t1.5108256237659907\n",
            "  (3, 6)\t1.5108256237659907\n",
            "  (3, 5)\t1.916290731874155\n",
            "  (3, 2)\t1.916290731874155\n",
            "  (3, 1)\t1.5108256237659907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXk-QYLwzJTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}